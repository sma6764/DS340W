{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install statsforecast==1.7.4 neuralforecast==1.6.4 utilsforecast==0.1.1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install statsforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/air-passengers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.38.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st \n",
    "st.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.24.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly as pt \n",
    "pt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.utils import AirPassengersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AirPassengersDF.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AirPassengersDF.to_csv('AirPassengersDF.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1949-01-31</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1949-02-28</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1949-03-31</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1949-04-30</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1949-05-31</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds      y\n",
       "0        1.0 1949-01-31  112.0\n",
       "1        1.0 1949-02-28  118.0\n",
       "2        1.0 1949-03-31  132.0\n",
       "3        1.0 1949-04-30  129.0\n",
       "4        1.0 1949-05-31  121.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AirPassengersDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsforecast\n",
    "statsforecast.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_statistical_model(df, seasonal_length, date_format, data_frequency, forecast_horizon, \n",
    "                             ignore_neg_fcsts, error_metric, eval):\n",
    "    df = df.copy()\n",
    "    print('under stats model', df.columns)\n",
    "    stats = StatsForecastModels(\n",
    "        seasonal_length=seasonal_length,\n",
    "        freq=data_frequency,\n",
    "        date_format=date_format,\n",
    "        )\n",
    "    \n",
    "    stats.fit(df)\n",
    "    df_pred = stats.predict(horizon=forecast_horizon, ignore_neg_fcsts=ignore_neg_fcsts)\n",
    "\n",
    "    if ( eval ):\n",
    "        df_crossval = stats.crossvalidation(error_metric=error_metric)\n",
    "        df_performance = evaluate_cross_validation(df_crossval, error_metric)\n",
    "        df_rank = rank_forecast(df_pred[df_pred['unique_id'].isin(df_performance.index)].reset_index(drop=True), df_performance)\n",
    "        \n",
    "        # ids_bucket_1 = list(( df.groupby('unique_id')['ds'].count()[ (df.groupby('unique_id')['ds'].count()<=27) & (df.groupby('unique_id')['ds'].count()>=12) ] ).index)\n",
    "\n",
    "        # if(len(ids_bucket_1)>0):\n",
    "        #     df_rank_bucket_1 = df_pred[df_pred['unique_id'].isin(ids_bucket_1)][['unique_id','ds','AutoTheta']].reset_index(drop=True)\n",
    "        #     df_rank_bucket_1.rename(columns={'AutoTheta':'forecast'},inplace=True)\n",
    "        #     df_rank_bucket_1['model'] = 'AutoTheta'\n",
    "        #     df_rank_bucket_1['rank'] = 1\n",
    "            \n",
    "        #     df_rank = pd.concat([df_rank_bucket_1,df_rank])\n",
    "    \n",
    "    else:\n",
    "        df_performance,df_rank,df_crossval = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    return df_pred, df_performance, df_crossval, df_rank\n",
    "\n",
    "\n",
    "def evaluate_cross_validation(df, metric):\n",
    "    error_metric = globals()[metric]\n",
    "    models = df.drop(columns=[\"unique_id\", \"ds\", \"cutoff\", \"y\"]).columns.tolist()\n",
    "    evals = []\n",
    "    for cutoff in df[\"cutoff\"].unique():\n",
    "        eval_ = evaluate(\n",
    "            df[df[\"cutoff\"] == cutoff], metrics=[error_metric], models=models\n",
    "        )\n",
    "        evals.append(eval_)\n",
    "    evaluated = pd.concat(evals)\n",
    "    evaluated = evaluated.groupby(\"unique_id\").mean(numeric_only=True)\n",
    "\n",
    "    evaluated.insert(0, \"best_model\", evaluated.idxmin(axis=1))\n",
    "    return evaluated\n",
    "\n",
    "\n",
    "def rank_forecast(pred__, evaluate__):\n",
    "\n",
    "    df_tmp_transform_ = evaluate__.reset_index().T.reset_index()\n",
    "    headers = df_tmp_transform_.iloc[0]\n",
    "    df_tmp_rank_ = pd.DataFrame(df_tmp_transform_.values[1:], columns=headers)\n",
    "    df_tmp_rank_.rename(columns={\"unique_id\": \"models\"}, inplace=True)\n",
    "    df_tmp_rank_ = df_tmp_rank_[df_tmp_rank_[\"models\"] != \"best_model\"].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    df_int_ = pd.DataFrame()\n",
    "    for id_ in evaluate__.index:\n",
    "        df_tmp_rank_[id_] = df_tmp_rank_[id_].astype(float)\n",
    "        df_tmp_ = df_tmp_rank_[[\"models\", id_]].sort_values(by=id_)\n",
    "        df_tmp_pred = pd.DataFrame()\n",
    "        rank = 1\n",
    "        for mdl_ in df_tmp_[\"models\"]:\n",
    "            df_tmp_pred = pred__[pred__[\"unique_id\"] == id_].reset_index(drop=True)[\n",
    "                [\"unique_id\", \"ds\"]\n",
    "            ]\n",
    "            df_tmp_pred[\"model\"] = mdl_\n",
    "            df_tmp_pred[\"forecast\"] = pred__[mdl_]\n",
    "            df_tmp_pred[\"rank\"] = rank\n",
    "            df_int_ = pd.concat([df_int_, df_tmp_pred], ignore_index=True)\n",
    "            rank += 1\n",
    "    \n",
    "    df_int_ = df_int_[~df_int_['forecast'].isna()].reset_index(drop=True)\n",
    "\n",
    "    return df_int_\n",
    "\n",
    "# def evaluate_cross_validation(df, metric):\n",
    "#     df = df.copy()\n",
    "#     error_metric = globals()[metric]\n",
    "#     models = df.drop(columns=[\"unique_id\", \"ds\", \"cutoff\", \"y\"]).columns.tolist()\n",
    "#     evals = []\n",
    "#     for cutoff in df[\"cutoff\"].unique():\n",
    "#         eval_ = evaluate(\n",
    "#             df[df[\"cutoff\"] == cutoff], metrics=[error_metric], models=models\n",
    "#         )\n",
    "#         evals.append(eval_)\n",
    "#     evaluated = pd.concat(evals)\n",
    "#     evaluated = evaluated.groupby(\"unique_id\").mean(numeric_only=True)\n",
    "\n",
    "#     evaluated.insert(0, \"best_model\", evaluated.idxmin(axis=1))\n",
    "#     return evaluated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_forecast_model(df, model_type, date_format, data_frequency, seasonal_length, forecast_horizon, ignore_neg_fcsts, error_metric, eval=True):\n",
    "    \n",
    "    if(model_type=='statistical'):\n",
    "        print('getting resulst for statsitcal model')\n",
    "        print(df.columns)\n",
    "        df_pred, df_performance, df_crossval, df_rank = train_statistical_model(df, seasonal_length, date_format, data_frequency, forecast_horizon, ignore_neg_fcsts, error_metric, eval)\n",
    "    return df_pred, df_performance, df_crossval, df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from statsforecast.models import (\n",
    "    AutoARIMA,\n",
    "    AutoETS,\n",
    "    AutoCES,\n",
    "    AutoTheta,\n",
    "    AutoRegressive,\n",
    "    SeasonalExponentialSmoothingOptimized,\n",
    "    Holt,\n",
    "    HoltWinters,\n",
    "    SeasonalWindowAverage,\n",
    "    RandomWalkWithDrift,\n",
    "    SeasonalNaive,\n",
    "    Naive\n",
    ")\n",
    "from utilsforecast.losses import smape, mape, mse, rmse, mae, rmae, mase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from utilsforecast.losses import smape, mape, mse, rmse, mae, rmae, mase\n",
    "from utilsforecast.evaluation import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from typing import Optional\n",
    "import warnings\n",
    "import cProfile\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from statsforecast.utils import ConformalIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# STATS_MDL = [\n",
    "#     \"AutoARIMA\",\n",
    "#     \"AutoETS\",\n",
    "#     \"AutoCES\",\n",
    "#     \"AutoTheta\",\n",
    "#     \"AutoRegressive\",\n",
    "#     \"SeasonalExponentialSmoothingOptimized\",\n",
    "#     \"Holt\",\n",
    "#     \"HoltWinters\",\n",
    "#     \"SeasonalNaive\",\n",
    "#     \"SeasonalWindowAverage\",\n",
    "#     \"RandomWalkWithDrift\",\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "MDL_PARAMETERS = {\n",
    "    \"AutoARIMA\": {\"season_length\": 1},\n",
    "    \"AutoETS\": {\"season_length\": 1},\n",
    "    \"AutoCES\": {\"season_length\": 1},\n",
    "    \"AutoTheta\": {\"season_length\": 1},\n",
    "    \"AutoRegressive\": {\"lags\": 1,\"include_drift\":True},\n",
    "    \"SeasonalExponentialSmoothingOptimized\": {\"season_length\": 1},\n",
    "    \"Holt\": {\"season_length\": 1, \"alias\":\"Holt\"},\n",
    "    \"HoltWinters\": {\"season_length\": 1, \"alias\":'HoltWinters'},\n",
    "    \"SeasonalNaive\": {\"season_length\": 1},\n",
    "    \"SeasonalWindowAverage\": {\"season_length\": 1, 'window_size':1}, \n",
    "}\n",
    "\n",
    "# ENSEMBLE_MAPPING = {\n",
    "#     \"stats_ensemble\": STATS_MDL\n",
    "# }\n",
    "\n",
    "# MDL_SPEED_MAPPING = {\n",
    "    \n",
    "#     \"all\": STATS_MDL,\n",
    "    \n",
    "#     \"test\": STATS_MDL\n",
    "# }\n",
    "\n",
    "MDL_RENAME_MAPPING = {\n",
    "    \"RWD\": \"RandomWalkWithDrift\",\n",
    "    \"CES\": \"AutoCES\",\n",
    "    \"SeasWA\": \"SeasonalWindowAverage\",\n",
    "    \"SES\": \"SimpleExponentialSmoothing\",\n",
    "    \"SESOpt\": \"SimpleExponentialSmoothingOptimized\",\n",
    "    \"SeasonalES\":\"SeasonalExponentialSmoothing\",\n",
    "    \"SeasESOpt\": \"SeasonalExponentialSmoothingOptimized\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class StatsForecastModels:\n",
    "    def __init__(\n",
    "        self, seasonal_length: int, freq: str, date_format: str\n",
    "    ) -> None:\n",
    "\n",
    "        self.models = [\n",
    "            \"AutoARIMA\",\n",
    "            \"AutoETS\",\n",
    "            \"AutoCES\",\n",
    "            \"AutoTheta\",\n",
    "            \"AutoRegressive\",\n",
    "            \"SeasonalExponentialSmoothingOptimized\",\n",
    "            \"Holt\",\n",
    "            \"HoltWinters\",\n",
    "            \"SeasonalNaive\",\n",
    "            \"SeasonalWindowAverage\",\n",
    "            \"RandomWalkWithDrift\",\n",
    "        ]\n",
    "\n",
    "        if( seasonal_length > 1):\n",
    "            self.models.remove('Holt')\n",
    "        else:\n",
    "            self.models.remove('HoltWinters')\n",
    "\n",
    "\n",
    "#         if len(set(self.models) - set(STATS_MDL)) != 0:\n",
    "#             mdl_np = \",\".join(list(set(model_type) - set(STATS_MDL)))\n",
    "#             raise Exception(mdl_np, \"models are not present in module\")\n",
    "\n",
    "        self.seasonal_length = seasonal_length\n",
    "        self.freq = freq\n",
    "        self.date_format = date_format\n",
    "        self.model_pos = None\n",
    "        self.ignore_neg_fcsts = False\n",
    "\n",
    "    def set_mdl_param(self):\n",
    "        if self.seasonal_length is not None:\n",
    "            for mdl_name, mdl_params in MDL_PARAMETERS.items():\n",
    "                if \"season_length\" in mdl_params.keys():\n",
    "                    mdl_params[\"season_length\"] = self.seasonal_length\n",
    "                if \"window_size\" in mdl_params.keys():\n",
    "                    window_size = int( (self.train_df.ds.nunique()*0.20) / self.seasonal_length )\n",
    "                    if(window_size<=1):\n",
    "                        mdl_params['window_size'] = 1\n",
    "                    else:\n",
    "                        mdl_params['window_size'] = window_size\n",
    "                        \n",
    "                if \"lags\" in mdl_params.keys():\n",
    "                    mdl_params[\"lags\"] = self.seasonal_length\n",
    "        \n",
    "    def data_validation(self):\n",
    "        try:\n",
    "#             date_mapping = {\"MM/DD/YYYY\": \"%m-%d-%Y\", \"DD/MM/YYYY\": \"%d-%m-%Y\", \"DD-MM-YYYY\": \"%d-%m-%Y\", \"MM-DD-YYYY\": \"%m-%d-%Y\", \"YYYY/MM/DD\": \"%Y-%m-%d\"}\n",
    "            date_mapping = {\"DD/MM/YYYY\": \"%d/%m/%Y\",\n",
    "                            \"MM/DD/YYYY\": \"%m/%d/%Y\",\n",
    "                            \"YYYY/MM/DD\": \"%Y/%m/%d\",\n",
    "                            \"DD-MM-YYYY\": \"%d-%m-%Y\",\n",
    "                            \"MM-DD-YYYY\": \"%m-%d-%Y\",\n",
    "                            \"YYYY-MM-DD\": \"%Y-%m-%d\",}\n",
    "    \n",
    "            self.train_df[\"ds\"] = pd.to_datetime(\n",
    "                self.train_df[\"ds\"], format=date_mapping[self.date_format]\n",
    "            )\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Invalid date format: {self.date_format}\")\n",
    "            return\n",
    "        \n",
    "        self.format_validation()\n",
    "        return None\n",
    "\n",
    "    def format_validation(self):\n",
    "        return None\n",
    "\n",
    "    def fit(self, train_df: pd.DataFrame):\n",
    "        self.train_df = train_df\n",
    "        \n",
    "        if((self.freq=='M') | (self.freq=='MS')):\n",
    "            self.ids_bucket_1 = list(( train_df.groupby('unique_id')['ds'].count()[(train_df.groupby('unique_id')['ds'].count()<=27)] ).index)\n",
    "            self.ids_bucket_2 = list(( train_df.groupby('unique_id')['ds'].count()[(train_df.groupby('unique_id')['ds'].count()<=35) & (train_df.groupby('unique_id')['ds'].count()>=28)] ).index)\n",
    "            self.ids_bucket_3 = list(( train_df.groupby('unique_id')['ds'].count()[(train_df.groupby('unique_id')['ds'].count()>=36)] ).index)\n",
    "\n",
    "        if(self.freq=='W'):\n",
    "            self.ids_bucket_1 = list(( train_df.groupby('unique_id')['ds'].count()[(train_df.groupby('unique_id')['ds'].count()<=12) & (train_df.groupby('unique_id')['ds'].count()>=4)] ).index)\n",
    "            self.ids_bucket_2 = list(( train_df.groupby('unique_id')['ds'].count()[ (train_df.groupby('unique_id')['ds'].count()>=13) ] ).index)\n",
    "            self.ids_bucket_3 = list([])\n",
    "            \n",
    "        \n",
    "        self.set_mdl_param()\n",
    "        \n",
    "        try:\n",
    "            self.data_validation()\n",
    "            selected_models = []\n",
    "            for model_name in self.models:\n",
    "                if model_name in MDL_PARAMETERS.keys():\n",
    "                    selected_models.append(\n",
    "                        globals()[model_name](**MDL_PARAMETERS[model_name])\n",
    "                    )\n",
    "                else:\n",
    "                    selected_models.append(globals()[model_name]())\n",
    "                                        \n",
    "            sf_naive = StatsForecast( \n",
    "                models=[Naive()],\n",
    "                freq=self.freq\n",
    "                )\n",
    "\n",
    "            self.sf_naive = sf_naive.fit(self.train_df)\n",
    "\n",
    "            if(len(self.ids_bucket_1)>0):\n",
    "                \n",
    "                sf = StatsForecast(\n",
    "                models=selected_models,\n",
    "                freq=self.freq,\n",
    "                fallback_model=Naive()\n",
    "                )\n",
    "                self.sf_bucket_1 = sf.fit(self.train_df[self.train_df['unique_id'].isin(self.ids_bucket_1)].reset_index(drop=True))\n",
    "                \n",
    "            if(len(self.ids_bucket_2)>0):\n",
    "            \n",
    "                sf = StatsForecast(\n",
    "                models=selected_models,\n",
    "                freq=self.freq,\n",
    "                fallback_model=Naive()\n",
    "                )\n",
    "                self.sf_bucket_2 =sf.fit(self.train_df[self.train_df['unique_id'].isin(self.ids_bucket_2)].reset_index(drop=True))\n",
    "            \n",
    "            if(len(self.ids_bucket_3)>0):\n",
    "                \n",
    "                sf = StatsForecast(\n",
    "                models=selected_models,\n",
    "                freq=self.freq,\n",
    "                fallback_model=Naive()\n",
    "                )\n",
    "                self.sf_bucket_3 = sf.fit(self.train_df[self.train_df['unique_id'].isin(self.ids_bucket_3)].reset_index(drop=True))\n",
    "\n",
    "                            \n",
    "            return self\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during fitting: {e}\")\n",
    "            return None\n",
    "\n",
    "    def predict(self, horizon: int,ignore_neg_fcsts = False):\n",
    "        \n",
    "        self.horizon = horizon\n",
    "        self.ignore_neg_fcsts = ignore_neg_fcsts\n",
    "        \n",
    "        self.pred__ = pd.DataFrame()\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if(len(self.ids_bucket_1)>0):\n",
    "                self.pred_bucket_1 = self.sf_bucket_1.predict(horizon).rename(columns=MDL_RENAME_MAPPING) \n",
    "                \n",
    "                mdl_rename = list(set(self.models) - set(self.pred_bucket_1.columns))\n",
    "                \n",
    "                if(len(mdl_rename)==1):\n",
    "                    self.pred_bucket_1 = self.pred_bucket_1.rename(columns={'Naive':mdl_rename[0]})\n",
    "                                        \n",
    "                self.pred__ = pd.concat([self.pred__,self.pred_bucket_1])\n",
    "    \n",
    "                \n",
    "            if(len(self.ids_bucket_2)>0):\n",
    "                self.pred_bucket_2 = self.sf_bucket_2.predict(horizon).rename(columns=MDL_RENAME_MAPPING) \n",
    "                \n",
    "                mdl_rename = list(set(self.models) - set(self.pred_bucket_2.columns))\n",
    "                \n",
    "                if(len(mdl_rename)==1):\n",
    "                    self.pred_bucket_2 = self.pred_bucket_2.rename(columns={'Naive':mdl_rename[0]})\n",
    "                        \n",
    "                self.pred__ = pd.concat([self.pred__,self.pred_bucket_2])\n",
    "            \n",
    "                        \n",
    "            if(len(self.ids_bucket_3)>0):\n",
    "                self.pred_bucket_3 = self.sf_bucket_3.predict(horizon).rename(columns=MDL_RENAME_MAPPING)\n",
    "                \n",
    "                mdl_rename = list(set(self.models) - set(self.pred_bucket_3.columns))\n",
    "                \n",
    "                if(len(mdl_rename)==1):\n",
    "                    self.pred_bucket_3 = self.pred_bucket_3.rename(columns={'Naive':mdl_rename[0]})\n",
    "                        \n",
    "                self.pred__ = pd.concat([self.pred__,self.pred_bucket_3])\n",
    "            \n",
    "\n",
    "            self.pred_naive = self.sf_naive.predict(horizon)\n",
    "\n",
    "            self.pred__ = self.pred__.merge(self.pred_naive,on=['unique_id','ds'],how='left').reset_index()\n",
    "\n",
    "\n",
    "            # model_columns = self.pred__.columns[2:-1].values\n",
    "            \n",
    "            def replace_with_nan(group):\n",
    "                for model in self.models:\n",
    "                    if( (group[model]!=group['Naive']).sum() == 0 ):\n",
    "                        group[model] = np.nan\n",
    "                return group\n",
    "\n",
    "            self.pred__ = self.pred__.groupby('unique_id').apply(replace_with_nan).reset_index(drop=True)\n",
    "\n",
    "            \n",
    "        except:\n",
    "            raise Exception(\"Model not fitted yet. Call fit method first.\")\n",
    "            \n",
    "        self.pred__['stats_ensemble'] = self.pred__[self.models].mean(axis=1).drop(columns='Naive')\n",
    "\n",
    "        self.model_pos = list((self.pred__[self.pred__.iloc[:,2:].columns] >= 0).all().index)\n",
    "\n",
    "        if(ignore_neg_fcsts == True):\n",
    "            self.pred__= self.pred__[['unique_id','ds'] + self.model_pos]\n",
    "\n",
    "        return self.pred__\n",
    "    \n",
    "\n",
    "    def crossvalidation(\n",
    "        self, error_metric: str, h: Optional[int] = None\n",
    "    ):\n",
    "        \n",
    "        crossvalidation_df = pd.DataFrame()\n",
    "\n",
    "        def replace_with_nan(group):\n",
    "                for model in self.models:\n",
    "                    if( (group[model]!=group['Naive']).sum() == 0 ):\n",
    "                        group[model] = np.nan\n",
    "                return group\n",
    "            \n",
    "        if(len(self.ids_bucket_2)>0):\n",
    "            \n",
    "            df_f = self.train_df[self.train_df['unique_id'].isin(self.ids_bucket_2)].reset_index(drop=True)\n",
    "            \n",
    "            if((self.freq=='M') | (self.freq=='MS')):\n",
    "                h = df_f.groupby('unique_id')['ds'].count().min() - 25\n",
    "            if(self.freq=='W'):\n",
    "                h = 4\n",
    "\n",
    "            sf_naive_ = StatsForecast( \n",
    "                models=[Naive()],\n",
    "                freq=self.freq,\n",
    "                verbose=True)\n",
    "            \n",
    "            df_cross_naive = sf_naive_.cross_validation(df=self.train_df[self.train_df['unique_id'].isin(self.ids_bucket_2)].reset_index(drop=True) , h=h).reset_index()\n",
    "\n",
    "            crossvalidation_df_bucket_2 = self.sf_bucket_2.cross_validation(h=h)\n",
    "\n",
    "            crossvalidation_df_bucket_2 = crossvalidation_df_bucket_2.reset_index().rename(\n",
    "                columns=MDL_RENAME_MAPPING\n",
    "            )\n",
    "\n",
    "            crossvalidation_df_bucket_2 = crossvalidation_df_bucket_2.merge(df_cross_naive[['unique_id','ds','Naive']],on=['unique_id','ds'],how='left')\n",
    "\n",
    "            crossvalidation_df_bucket_2 = crossvalidation_df_bucket_2.groupby('unique_id').apply(replace_with_nan).reset_index(drop=True)\n",
    "            \n",
    "            crossvalidation_df = pd.concat([crossvalidation_df,crossvalidation_df_bucket_2])\n",
    "            \n",
    "        if(len(self.ids_bucket_3)>0):\n",
    "\n",
    "            if((self.freq=='M') | (self.freq=='MS')): \n",
    "                h = 12\n",
    "            if(self.freq=='W'): \n",
    "                h = 4\n",
    "\n",
    "            sf_naive_ = StatsForecast( \n",
    "                models=[Naive()],\n",
    "                freq=self.freq,\n",
    "                verbose=True)\n",
    "\n",
    "            df_cross_naive = sf_naive_.cross_validation(df=self.train_df[self.train_df['unique_id'].isin(self.ids_bucket_3)].reset_index(drop=True) ,h=h).reset_index()\n",
    "\n",
    "            crossvalidation_df_bucket_3 = self.sf_bucket_3.cross_validation(h=h)\n",
    "\n",
    "            crossvalidation_df_bucket_3 = crossvalidation_df_bucket_3.reset_index().rename(\n",
    "                columns=MDL_RENAME_MAPPING\n",
    "            )\n",
    "\n",
    "            crossvalidation_df_bucket_3 = crossvalidation_df_bucket_3.merge(df_cross_naive[['unique_id','ds','Naive']],on=['unique_id','ds'],how='left')\n",
    "\n",
    "            crossvalidation_df_bucket_3 = crossvalidation_df_bucket_3.groupby('unique_id').apply(replace_with_nan).reset_index(drop=True)\n",
    "            \n",
    "            crossvalidation_df = pd.concat([crossvalidation_df,crossvalidation_df_bucket_3])\n",
    "\n",
    "        if( (len(self.ids_bucket_3)>0) | (len(self.ids_bucket_2)>0) ):\n",
    "            \n",
    "            crossvalidation_df['stats_ensemble'] = crossvalidation_df[self.models].mean(axis=1)\n",
    "\n",
    "            if(self.ignore_neg_fcsts):\n",
    "                crossvalidation_df = crossvalidation_df[['unique_id','ds','cutoff','y']+self.model_pos]\n",
    "\n",
    "        return crossvalidation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting resulst for statsitcal model\n",
      "Index(['unique_id', 'ds', 'y'], dtype='object')\n",
      "under stats model Index(['unique_id', 'ds', 'y'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross Validation Time Series 1: 100%|██████████| 1/1 [00:00<00:00, 14979.66it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pred, df_performance, df_crossval, df_rank = build_forecast_model(df=AirPassengersDF, model_type='statistical', date_format='YYYY-MM-DD', data_frequency='M', seasonal_length=12, forecast_horizon=16, ignore_neg_fcsts=False, error_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoETS</th>\n",
       "      <th>AutoCES</th>\n",
       "      <th>AutoTheta</th>\n",
       "      <th>AutoRegressive</th>\n",
       "      <th>SeasonalExponentialSmoothingOptimized</th>\n",
       "      <th>HoltWinters</th>\n",
       "      <th>SeasonalNaive</th>\n",
       "      <th>SeasonalWindowAverage</th>\n",
       "      <th>RandomWalkWithDrift</th>\n",
       "      <th>Naive</th>\n",
       "      <th>stats_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-01-31</td>\n",
       "      <td>447.836945</td>\n",
       "      <td>442.357178</td>\n",
       "      <td>453.034180</td>\n",
       "      <td>442.940796</td>\n",
       "      <td>460.672668</td>\n",
       "      <td>416.427979</td>\n",
       "      <td>453.088745</td>\n",
       "      <td>417.0</td>\n",
       "      <td>388.5</td>\n",
       "      <td>434.237762</td>\n",
       "      <td>432.0</td>\n",
       "      <td>435.609619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-02-28</td>\n",
       "      <td>423.679565</td>\n",
       "      <td>428.267365</td>\n",
       "      <td>429.340393</td>\n",
       "      <td>432.229370</td>\n",
       "      <td>423.261719</td>\n",
       "      <td>390.507568</td>\n",
       "      <td>427.476532</td>\n",
       "      <td>391.0</td>\n",
       "      <td>366.5</td>\n",
       "      <td>436.475525</td>\n",
       "      <td>432.0</td>\n",
       "      <td>414.873779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-03-31</td>\n",
       "      <td>453.336334</td>\n",
       "      <td>492.974792</td>\n",
       "      <td>488.644714</td>\n",
       "      <td>495.306091</td>\n",
       "      <td>445.753448</td>\n",
       "      <td>418.865601</td>\n",
       "      <td>460.631775</td>\n",
       "      <td>419.0</td>\n",
       "      <td>412.5</td>\n",
       "      <td>438.713287</td>\n",
       "      <td>432.0</td>\n",
       "      <td>452.572601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-04-30</td>\n",
       "      <td>496.538574</td>\n",
       "      <td>477.369995</td>\n",
       "      <td>500.289551</td>\n",
       "      <td>482.306244</td>\n",
       "      <td>472.159729</td>\n",
       "      <td>460.345215</td>\n",
       "      <td>497.036804</td>\n",
       "      <td>461.0</td>\n",
       "      <td>428.5</td>\n",
       "      <td>440.951050</td>\n",
       "      <td>432.0</td>\n",
       "      <td>471.649719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-05-31</td>\n",
       "      <td>508.468170</td>\n",
       "      <td>477.602814</td>\n",
       "      <td>519.799622</td>\n",
       "      <td>487.493134</td>\n",
       "      <td>507.811127</td>\n",
       "      <td>471.474304</td>\n",
       "      <td>507.507538</td>\n",
       "      <td>472.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>443.188812</td>\n",
       "      <td>432.0</td>\n",
       "      <td>484.134583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds   AutoARIMA     AutoETS     AutoCES   AutoTheta  \\\n",
       "0        1.0 1961-01-31  447.836945  442.357178  453.034180  442.940796   \n",
       "1        1.0 1961-02-28  423.679565  428.267365  429.340393  432.229370   \n",
       "2        1.0 1961-03-31  453.336334  492.974792  488.644714  495.306091   \n",
       "3        1.0 1961-04-30  496.538574  477.369995  500.289551  482.306244   \n",
       "4        1.0 1961-05-31  508.468170  477.602814  519.799622  487.493134   \n",
       "\n",
       "   AutoRegressive  SeasonalExponentialSmoothingOptimized  HoltWinters  \\\n",
       "0      460.672668                             416.427979   453.088745   \n",
       "1      423.261719                             390.507568   427.476532   \n",
       "2      445.753448                             418.865601   460.631775   \n",
       "3      472.159729                             460.345215   497.036804   \n",
       "4      507.811127                             471.474304   507.507538   \n",
       "\n",
       "   SeasonalNaive  SeasonalWindowAverage  RandomWalkWithDrift  Naive  \\\n",
       "0          417.0                  388.5           434.237762  432.0   \n",
       "1          391.0                  366.5           436.475525  432.0   \n",
       "2          419.0                  412.5           438.713287  432.0   \n",
       "3          461.0                  428.5           440.951050  432.0   \n",
       "4          472.0                  446.0           443.188812  432.0   \n",
       "\n",
       "   stats_ensemble  \n",
       "0      435.609619  \n",
       "1      414.873779  \n",
       "2      452.572601  \n",
       "3      471.649719  \n",
       "4      484.134583  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_model</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoETS</th>\n",
       "      <th>AutoCES</th>\n",
       "      <th>AutoTheta</th>\n",
       "      <th>AutoRegressive</th>\n",
       "      <th>SeasonalExponentialSmoothingOptimized</th>\n",
       "      <th>HoltWinters</th>\n",
       "      <th>SeasonalNaive</th>\n",
       "      <th>SeasonalWindowAverage</th>\n",
       "      <th>RandomWalkWithDrift</th>\n",
       "      <th>Naive</th>\n",
       "      <th>stats_ensemble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>AutoCES</td>\n",
       "      <td>23.955328</td>\n",
       "      <td>40.083622</td>\n",
       "      <td>14.657907</td>\n",
       "      <td>24.985178</td>\n",
       "      <td>33.507935</td>\n",
       "      <td>51.147297</td>\n",
       "      <td>26.228498</td>\n",
       "      <td>50.708317</td>\n",
       "      <td>73.446129</td>\n",
       "      <td>92.666359</td>\n",
       "      <td>102.97654</td>\n",
       "      <td>34.97551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          best_model  AutoARIMA    AutoETS    AutoCES  AutoTheta  \\\n",
       "unique_id                                                          \n",
       "1.0          AutoCES  23.955328  40.083622  14.657907  24.985178   \n",
       "\n",
       "           AutoRegressive  SeasonalExponentialSmoothingOptimized  HoltWinters  \\\n",
       "unique_id                                                                       \n",
       "1.0             33.507935                              51.147297    26.228498   \n",
       "\n",
       "           SeasonalNaive  SeasonalWindowAverage  RandomWalkWithDrift  \\\n",
       "unique_id                                                              \n",
       "1.0            50.708317              73.446129            92.666359   \n",
       "\n",
       "               Naive  stats_ensemble  \n",
       "unique_id                             \n",
       "1.0        102.97654        34.97551  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>AutoETS</th>\n",
       "      <th>AutoCES</th>\n",
       "      <th>AutoTheta</th>\n",
       "      <th>AutoRegressive</th>\n",
       "      <th>SeasonalExponentialSmoothingOptimized</th>\n",
       "      <th>HoltWinters</th>\n",
       "      <th>SeasonalNaive</th>\n",
       "      <th>SeasonalWindowAverage</th>\n",
       "      <th>RandomWalkWithDrift</th>\n",
       "      <th>Naive</th>\n",
       "      <th>stats_ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1960-01-31</td>\n",
       "      <td>1959-12-31</td>\n",
       "      <td>417.0</td>\n",
       "      <td>424.160156</td>\n",
       "      <td>406.651276</td>\n",
       "      <td>410.827393</td>\n",
       "      <td>412.711884</td>\n",
       "      <td>393.031372</td>\n",
       "      <td>359.797455</td>\n",
       "      <td>409.680145</td>\n",
       "      <td>360.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>407.236633</td>\n",
       "      <td>405.0</td>\n",
       "      <td>393.409607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1960-02-29</td>\n",
       "      <td>1959-12-31</td>\n",
       "      <td>391.0</td>\n",
       "      <td>407.081696</td>\n",
       "      <td>401.732910</td>\n",
       "      <td>391.996124</td>\n",
       "      <td>404.640472</td>\n",
       "      <td>374.763031</td>\n",
       "      <td>341.758270</td>\n",
       "      <td>390.044067</td>\n",
       "      <td>342.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>409.473297</td>\n",
       "      <td>405.0</td>\n",
       "      <td>379.348999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1960-03-31</td>\n",
       "      <td>1959-12-31</td>\n",
       "      <td>419.0</td>\n",
       "      <td>470.860535</td>\n",
       "      <td>456.289642</td>\n",
       "      <td>456.414459</td>\n",
       "      <td>466.810883</td>\n",
       "      <td>408.308929</td>\n",
       "      <td>405.559357</td>\n",
       "      <td>448.929810</td>\n",
       "      <td>406.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>411.709930</td>\n",
       "      <td>405.0</td>\n",
       "      <td>431.488342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1960-04-30</td>\n",
       "      <td>1959-12-31</td>\n",
       "      <td>461.0</td>\n",
       "      <td>460.913605</td>\n",
       "      <td>440.870514</td>\n",
       "      <td>447.666779</td>\n",
       "      <td>449.600372</td>\n",
       "      <td>403.529755</td>\n",
       "      <td>395.519958</td>\n",
       "      <td>435.445007</td>\n",
       "      <td>396.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>413.946564</td>\n",
       "      <td>405.0</td>\n",
       "      <td>421.549255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1960-05-31</td>\n",
       "      <td>1959-12-31</td>\n",
       "      <td>472.0</td>\n",
       "      <td>484.900879</td>\n",
       "      <td>440.333923</td>\n",
       "      <td>472.150970</td>\n",
       "      <td>454.047760</td>\n",
       "      <td>444.491333</td>\n",
       "      <td>419.429169</td>\n",
       "      <td>454.699951</td>\n",
       "      <td>420.0</td>\n",
       "      <td>391.5</td>\n",
       "      <td>416.183197</td>\n",
       "      <td>405.0</td>\n",
       "      <td>439.773743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds     cutoff      y   AutoARIMA     AutoETS     AutoCES  \\\n",
       "0        1.0 1960-01-31 1959-12-31  417.0  424.160156  406.651276  410.827393   \n",
       "1        1.0 1960-02-29 1959-12-31  391.0  407.081696  401.732910  391.996124   \n",
       "2        1.0 1960-03-31 1959-12-31  419.0  470.860535  456.289642  456.414459   \n",
       "3        1.0 1960-04-30 1959-12-31  461.0  460.913605  440.870514  447.666779   \n",
       "4        1.0 1960-05-31 1959-12-31  472.0  484.900879  440.333923  472.150970   \n",
       "\n",
       "    AutoTheta  AutoRegressive  SeasonalExponentialSmoothingOptimized  \\\n",
       "0  412.711884      393.031372                             359.797455   \n",
       "1  404.640472      374.763031                             341.758270   \n",
       "2  466.810883      408.308929                             405.559357   \n",
       "3  449.600372      403.529755                             395.519958   \n",
       "4  454.047760      444.491333                             419.429169   \n",
       "\n",
       "   HoltWinters  SeasonalNaive  SeasonalWindowAverage  RandomWalkWithDrift  \\\n",
       "0   409.680145          360.0                  350.0           407.236633   \n",
       "1   390.044067          342.0                  330.0           409.473297   \n",
       "2   448.929810          406.0                  384.0           411.709930   \n",
       "3   435.445007          396.0                  372.0           413.946564   \n",
       "4   454.699951          420.0                  391.5           416.183197   \n",
       "\n",
       "   Naive  stats_ensemble  \n",
       "0  405.0      393.409607  \n",
       "1  405.0      379.348999  \n",
       "2  405.0      431.488342  \n",
       "3  405.0      421.549255  \n",
       "4  405.0      439.773743  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crossval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>model</th>\n",
       "      <th>forecast</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-01-31</td>\n",
       "      <td>AutoCES</td>\n",
       "      <td>453.034180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-02-28</td>\n",
       "      <td>AutoCES</td>\n",
       "      <td>429.340393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-03-31</td>\n",
       "      <td>AutoCES</td>\n",
       "      <td>488.644714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-04-30</td>\n",
       "      <td>AutoCES</td>\n",
       "      <td>500.289551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-05-31</td>\n",
       "      <td>AutoCES</td>\n",
       "      <td>519.799622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds    model    forecast  rank\n",
       "0        1.0 1961-01-31  AutoCES  453.034180     1\n",
       "1        1.0 1961-02-28  AutoCES  429.340393     1\n",
       "2        1.0 1961-03-31  AutoCES  488.644714     1\n",
       "3        1.0 1961-04-30  AutoCES  500.289551     1\n",
       "4        1.0 1961-05-31  AutoCES  519.799622     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from io import BytesIO\n",
    "# Import your forecasting model libraries here, e.g., Prophet, ARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      👋 \u001b[1mWelcome to Streamlit!\u001b[0m\n",
      "\n",
      "      If you’d like to receive helpful onboarding emails, news, offers, promotions,\n",
      "      and the occasional swag, please enter your email address below. Otherwise,\n",
      "      leave this field blank.\n",
      "\n",
      "      \u001b[34mEmail: \u001b[0m ^C\n",
      "2024-11-08 14:17:28.600 \n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('air-passengers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   unique_id  144 non-null    object\n",
      " 1   ds         144 non-null    object\n",
      " 2   y          144 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1949-01-01</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1949-02-01</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1949-03-01</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1949-04-01</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1949-05-01</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_id          ds    y\n",
       "0  AirPassengers  1949-01-01  112\n",
       "1  AirPassengers  1949-02-01  118\n",
       "2  AirPassengers  1949-03-01  132\n",
       "3  AirPassengers  1949-04-01  129\n",
       "4  AirPassengers  1949-05-01  121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>144</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1954-12-16 05:00:00</td>\n",
       "      <td>280.298611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1949-01-01 00:00:00</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1951-12-24 06:00:00</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1954-12-16 12:00:00</td>\n",
       "      <td>265.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1957-12-08 18:00:00</td>\n",
       "      <td>360.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1960-12-01 00:00:00</td>\n",
       "      <td>622.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>119.966317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ds           y\n",
       "count                  144  144.000000\n",
       "mean   1954-12-16 05:00:00  280.298611\n",
       "min    1949-01-01 00:00:00  104.000000\n",
       "25%    1951-12-24 06:00:00  180.000000\n",
       "50%    1954-12-16 12:00:00  265.500000\n",
       "75%    1957-12-08 18:00:00  360.500000\n",
       "max    1960-12-01 00:00:00  622.000000\n",
       "std                    NaN  119.966317"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        unique_id         ds     y\n",
      "0   AirPassengers 1961-01-01  None\n",
      "1   AirPassengers 1961-02-01  None\n",
      "2   AirPassengers 1961-03-01  None\n",
      "3   AirPassengers 1961-04-01  None\n",
      "4   AirPassengers 1961-05-01  None\n",
      "5   AirPassengers 1961-06-01  None\n",
      "6   AirPassengers 1961-07-01  None\n",
      "7   AirPassengers 1961-08-01  None\n",
      "8   AirPassengers 1961-09-01  None\n",
      "9   AirPassengers 1961-10-01  None\n",
      "10  AirPassengers 1961-11-01  None\n",
      "11  AirPassengers 1961-12-01  None\n"
     ]
    }
   ],
   "source": [
    "next_dates = pd.date_range(df['ds'].iloc[-1], periods=13, freq='MS')[1:]\n",
    "next_df = pd.DataFrame({\n",
    "    'unique_id': ['AirPassengers'] * 12,\n",
    "    'ds': next_dates,\n",
    "    'y': [None] * 12  # No values for 'y' yet\n",
    "})\n",
    "print(next_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.16358273904128498,\n",
       " -0.0654256827131722,\n",
       " 2.15631965714235,\n",
       " 0.15671439031900888,\n",
       " 0.42495577088873454,\n",
       " -1.0603430872777562,\n",
       " 0.23324347105152354,\n",
       " 1.010772711438264,\n",
       " -0.9020784786230626,\n",
       " 1.04290777123561,\n",
       " 1.7493107172722036,\n",
       " -2.1962222564138796]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.random.randn(12).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Model_ARIMA\", \"Model_Prophet\", \"Model_LSTM\"]  # Replace with actual model names\n",
    "forecast_horizon = 12 \n",
    "\n",
    "forecast_results = pd.DataFrame()\n",
    "forecast_results[f'ds'] = pd.date_range(df['ds'].iloc[-1], periods=forecast_horizon+1, freq='MS')[1:]\n",
    "forecast_results[f'unique_id']= df['unique_id'][:forecast_horizon]\n",
    "for model in models:\n",
    "    forecast_results[model] = np.random.randn(forecast_horizon).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1960-08-01</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1960-09-01</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1960-10-01</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1960-11-01</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1960-12-01</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id         ds    y\n",
       "139  AirPassengers 1960-08-01  606\n",
       "140  AirPassengers 1960-09-01  508\n",
       "141  AirPassengers 1960-10-01  461\n",
       "142  AirPassengers 1960-11-01  390\n",
       "143  AirPassengers 1960-12-01  432"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>Model_ARIMA</th>\n",
       "      <th>Model_Prophet</th>\n",
       "      <th>Model_LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961-01-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1.553429</td>\n",
       "      <td>1.158864</td>\n",
       "      <td>-0.338632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961-02-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>-0.128835</td>\n",
       "      <td>0.456952</td>\n",
       "      <td>0.086386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961-03-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>0.709753</td>\n",
       "      <td>-0.024270</td>\n",
       "      <td>-0.181842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961-04-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>-1.450626</td>\n",
       "      <td>0.769838</td>\n",
       "      <td>0.486375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961-05-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>-1.232098</td>\n",
       "      <td>0.235793</td>\n",
       "      <td>0.242796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1961-06-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>-0.892027</td>\n",
       "      <td>-0.108596</td>\n",
       "      <td>-1.186534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1961-07-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>0.222959</td>\n",
       "      <td>-0.625139</td>\n",
       "      <td>-0.958414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1961-08-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1.907500</td>\n",
       "      <td>-0.740632</td>\n",
       "      <td>-0.060123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1961-09-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1.068454</td>\n",
       "      <td>0.103857</td>\n",
       "      <td>0.264537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1961-10-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>0.693684</td>\n",
       "      <td>-0.176851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1961-11-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>0.669949</td>\n",
       "      <td>0.723148</td>\n",
       "      <td>-2.034187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1961-12-01</td>\n",
       "      <td>AirPassengers</td>\n",
       "      <td>1.296508</td>\n",
       "      <td>-0.068325</td>\n",
       "      <td>-0.540490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ds      unique_id  Model_ARIMA  Model_Prophet  Model_LSTM\n",
       "0  1961-01-01  AirPassengers     1.553429       1.158864   -0.338632\n",
       "1  1961-02-01  AirPassengers    -0.128835       0.456952    0.086386\n",
       "2  1961-03-01  AirPassengers     0.709753      -0.024270   -0.181842\n",
       "3  1961-04-01  AirPassengers    -1.450626       0.769838    0.486375\n",
       "4  1961-05-01  AirPassengers    -1.232098       0.235793    0.242796\n",
       "5  1961-06-01  AirPassengers    -0.892027      -0.108596   -1.186534\n",
       "6  1961-07-01  AirPassengers     0.222959      -0.625139   -0.958414\n",
       "7  1961-08-01  AirPassengers     1.907500      -0.740632   -0.060123\n",
       "8  1961-09-01  AirPassengers     1.068454       0.103857    0.264537\n",
       "9  1961-10-01  AirPassengers    -0.022451       0.693684   -0.176851\n",
       "10 1961-11-01  AirPassengers     0.669949       0.723148   -2.034187\n",
       "11 1961-12-01  AirPassengers     1.296508      -0.068325   -0.540490"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
